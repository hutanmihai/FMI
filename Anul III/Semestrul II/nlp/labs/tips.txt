Rezumat Laborator 1 grupa 1 (Marius)


ÃntrebÄƒri despre modul de notare
Q: DacÄƒ facem survey, cum ar trebui sÄƒ arate, despre ce e vorba?
A: Exemplu de survey: https://arxiv.org/pdf/2402.06196.pdf . Am ales acest articol È™i ca sÄƒ vedeÈ›i starea actualÄƒ a domeniului Ã®n legÄƒturÄƒ cu LLMs. Ar trebui sÄƒ arÄƒtaÈ›i sistematic rezultatele dintr-o ramurÄƒ a NLP.

Q: CÃ¢t de mult ar trebui intrat Ã®n detaliu la un survey?
A: Nu este nevoie sÄƒ fie atÃ¢t de riguros È™i de elaborat ca articolele din literaturÄƒ.

Q: RecomandÄƒri de cÄƒrÈ›i?
A: Cea mai recentÄƒ ar fi SLP3 ( https://web.stanford.edu/~jurafsky/slp3/ ), apoi mai general AIMA (dar ultima ediÈ›ie e "veche" pt NLP, din 2020; https://aima.cs.berkeley.edu/ ). Pentru introducere Ã®n lingvisticÄƒ, recomand cartea Language Files (am pus ediÈ›ia 12 pe Teams). Ping us dacÄƒ aveÈ›i nevoie de ajutor sÄƒ faceÈ›i rost de cÄƒrÈ›i ğŸ˜‡ï¸

Q: Un plan de Ã®nvÄƒÈ›at ce e Ã®n acele cÄƒrÈ›i?
A: Poate fi prea mult dacÄƒ ai Ã®ncepe cu Ã®nceputul. O variantÄƒ e sÄƒ Ã®ncepi cu cele mai recente lucruri care te intereseazÄƒ È™i de acolo sÄƒ faci backtracking pe ce nu cunoÈ™ti. De asemenea... ÃNTREBAÈšI, ÃNTREBAÈšI, ÃNTREBAÈšI! De asta suntem aici :)


ÃntrebÄƒri despre implementÄƒri
Q: DacÄƒ e sÄƒ reproducem un articol din literaturÄƒ, putem lua codul autorilor sau trebuie reimplementat de la 0? DacÄƒ luÄƒm codul existent, unde mai e originalitatea? Cu ce am putea contribui Ã®n domeniu? Ce ne facem dacÄƒ Ã®n articol ei au antrenat pe multe GPUs È™i noi nu avem astfel de resurse?
A: Ca exemplu de reprodus experimente, vezi https://repronlp.github.io/ .
Pentru ediÈ›ia din 2023, vezi https://aclanthology.org/volumes/2023.humeval-1/ ( https://humeval.github.io/2023/ ).
Pentru ediÈ›ia din 2022, vezi https://aclanthology.org/volumes/2022.inlg-genchal/ ( https://reprogen.github.io/2022/accepted-papers/ ).

DacÄƒ ne uitÄƒm pe acele articole, vedem cÄƒ apar probleme chiar È™i Ã®n condiÈ›iile Ã®n care avem toate datele È™i tot codul. Zona asta e "active research area", e mult loc de Ã®mbunÄƒtÄƒÈ›ire.

Ãn legÄƒturÄƒ cu ultimele 2 Ã®ntrebÄƒri, fac shameless plug (Marius): https://ceur-ws.org/Vol-3473/paper44.pdf
Legat de resurse, am obÈ›inut rezultate bune antrenÃ¢nd/fÄƒcÃ¢nd inferenÈ›Äƒ doar pe un laptop obiÈ™nuit. PuteÈ›i Ã®ncerca modele mai mici È™i chiar È™i aÈ™a, ar trebui sÄƒ obÈ›ineÈ›i rezultate acceptabile.
Legat de originalitate, am venit cu o idee de implementat relation extraction folosind doar modele de NER È™i postprocesare pe ideea cÄƒ era ineficient È™i/sau complicat de adaptat codul altcuiva. De ce? Spre deosebire de NER, pentru relation extraction nu (prea) existÄƒ implementÄƒri Ã®n biblioteci deoarece sunt foarte multe particularitÄƒÈ›i È™i depinde de fiecare caz Ã®n parte. Detalii despre NER mai jos/Ã®n alte laboratoare/cursuri.


Q: Ce pretenÈ›ii sunt de la shared tasks, ce ar trebui sÄƒ facem sÄƒ Ã®ncepem cercetarea Ã®n domeniu?
A: VedeÈ›i shared tasks cu deadlines mai permisive


Alte Ã®ntrebÄƒri
Q: DacÄƒ LLMs se descurcÄƒ aÈ™a bine, ce mai e de fÄƒcut Ã®n domeniu?
A: Vezi shared tasks de anul acesta, survey-ul de la Ã®nceput È™i aceastÄƒ prezentare de la Evalita: https://drive.google.com/file/d/1pe5jrYP_BPdpSSGPdvByNTZvRsJlRX86/view
TL;DR Ã®ncÄƒ sunt destule probleme È™i cu LLM-urile, nu s-a terminat (nici pe departe) domeniul. Chiar dacÄƒ s-au rezolvat multe probleme (Ã®n mare parte), au apÄƒrut altele.

O problemÄƒ majorÄƒ de actualitate este contaminarea modelelor. Ideea ar fi sÄƒ nu evaluezi pe seturi de date publice pt cÄƒ modelele a la GPT-4 au fÄƒcut scrape la "tot internetul", deci probabil au vÄƒzut deja È™i exemplele pe care ai testa (dacÄƒ le-ai publicat). Multe modele de acum se evalueazÄƒ pe benchmark-ul HF4 ( https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard ), aici e alt loc unde puteÈ›i gÄƒsi ce mai e nou Ã®n domeniu. Pe de altÄƒ parte, din unele discuÈ›ii pare cÄƒ È™i multe modele din acest benchmark suferÄƒ de data contamination. AÈ™adar, mai e mult pÃ¢nÄƒ se rezolvÄƒ aceastÄƒ problemÄƒ.
Un articol Ã®n glumÄƒ pe tema asta: https://arxiv.org/pdf/2309.08632.pdf

Q: LLMs nu gÃ¢ndesc, se comportÄƒ ca niÈ™te hash tables imense. Corect?
A: DacÄƒ primeam aceastÄƒ Ã®ntrebare acum 1-2 sÄƒptÄƒmÃ¢ni, eram "mai de acord". Ãntre timp, am dat de acest articol acceptat ca poster la ICLR 2023 ( https://arxiv.org/abs/2210.13382 ) care aratÄƒ cÄƒ o reÈ›ea cu arhitecturÄƒ GPT nu toceÈ™te, ci pare sÄƒ formeze o reprezentare internÄƒ pentru ce are de fÄƒcut. PerturbÃ¢nd anumite straturi din reÈ›ea, ei aratÄƒ cÄƒ acea reprezentare este validÄƒ È™i "face ce trebuie", nu doar toceÈ™te.
Pe de altÄƒ parte, acela este un exemplu "de jucÄƒrie" ca sÄƒ fie mai uÈ™or de analizat ce se Ã®ntÃ¢mplÄƒ Ã®n straturile reÈ›elei. Ãn task-uri mai complicate, din ce am observat cu participarea la SemEval (task 7) de anul acesta, reÈ›elele tot au tendinÈ›a sÄƒ formeze euristici pentru a ajunge "mai simplu" la un rÄƒspuns, ceea ce ar Ã®nsemna cÄƒ reprezentÄƒrile pe care le Ã®nvaÈ›Äƒ nu sunt corecte Ã®n toate situaÈ›iile. Cu alte cuvinte, chiar dacÄƒ nu e "tocealÄƒ", nu Ã®nseamnÄƒ cÄƒ Ã®nvaÈ›Äƒ ce ne-am aÈ™tepta noi sÄƒ Ã®nveÈ›e.





