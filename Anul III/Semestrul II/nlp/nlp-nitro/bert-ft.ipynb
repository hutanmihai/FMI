{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer, AutoModelForSequenceClassification\n",
    "from constants import TRAIN_CSV, TEST_CSV, MODELS_PATH, RESULTS_PATH, LOGS_PATH "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add seed for reproducibility"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92e0041565cf646a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb912b188328b39",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def reset_numpy_seed(seed_value=42):\n",
    "    try:\n",
    "        # Set NumPy random seed\n",
    "        import numpy as np\n",
    "\n",
    "        np.random.seed(seed_value)\n",
    "        print(f\"NumPy random seed set with value: {seed_value}\")\n",
    "    except Exception as e:\n",
    "        print(f\"NumPy random seed was not set: {e}\")\n",
    "    return\n",
    "\n",
    "\n",
    "def reset_torch_seed(seed_value=42):\n",
    "    try:\n",
    "        # Set PyTorch random seed\n",
    "        import torch\n",
    "\n",
    "        torch.manual_seed(seed_value)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed(seed_value)\n",
    "            torch.cuda.manual_seed_all(seed_value)  # if you are using multiple GPUs\n",
    "        print(f\"PyTorch random seed set with value: {seed_value}\")\n",
    "    except Exception as e:\n",
    "        print(f\"PyTorch random seed was not set: {e}\")\n",
    "    return\n",
    "\n",
    "\n",
    "def set_random_seeds(seed_value=42):\n",
    "    # Set Python random seed\n",
    "    random.seed(seed_value)\n",
    "    reset_numpy_seed(seed_value)\n",
    "    reset_torch_seed(seed_value)\n",
    "    return\n",
    "\n",
    "\n",
    "# Set the desired seed value\n",
    "seed = 42\n",
    "\n",
    "# Set random seeds\n",
    "set_random_seeds(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the data and add special tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc06080e159bad9a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea414507c3e27ef",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "replacements = {\"ţ\": \"ț\", \"ş\": \"ș\", \"Ţ\": \"Ț\", \"Ş\": \"Ș\"}\n",
    "df_train[\"title\"] = df_train[\"title\"].replace(replacements, regex=True)\n",
    "df_train[\"content\"] = df_train[\"content\"].replace(replacements, regex=True)\n",
    "df_test[\"title\"] = df_test[\"title\"].replace(replacements, regex=True)\n",
    "df_test[\"content\"] = df_test[\"content\"].replace(replacements, regex=True)\n",
    "SEP_TOKEN = \" [SEP] \"\n",
    "TITLE_TOKEN = \" [TITLE] \"\n",
    "CONTENT_TOKEN = \" [CONTENT] \"\n",
    "\n",
    "df_train[\"title\"] = df_train[\"title\"].fillna('')\n",
    "df_train[\"content\"] = df_train[\"content\"].fillna('')\n",
    "df_train[\"input\"] = TITLE_TOKEN + df_train[\"title\"] + SEP_TOKEN + CONTENT_TOKEN + df_train[\"content\"]\n",
    "\n",
    "df_test[\"title\"] = df_test[\"title\"].fillna('')\n",
    "df_test[\"content\"] = df_test[\"content\"].fillna('')\n",
    "df_test[\"input\"] =  TITLE_TOKEN + df_test[\"title\"] + SEP_TOKEN +  CONTENT_TOKEN + df_test[\"content\"]\n",
    "\n",
    "df_train.drop([\"title\", \"content\"], axis=1, inplace=True)\n",
    "df_test.drop([\"title\", \"content\"], axis=1, inplace=True)\n",
    "df_train[\"class\"] = df_train[\"class\"].astype(int)\n",
    "df_train[\"input\"] = df_train[\"input\"].astype(str)\n",
    "df_test[\"input\"] = df_test[\"input\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e04de5-21ad-431e-b6f3-ae90f03ba5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for index in range(len(df_train)):\n",
    "    if df_train.iloc[index][\"input\"] == \"nan\":\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1506a9dc8d7c7ac2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bf5716331de36f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stefan Dumitrescu, Andrei-Marius Avram, and Sampo Pyysalo. 2020. The birth of Romanian BERT. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 4324–4328, Online. Association for Computational Linguistics.\n",
    "# https://huggingface.co/dumitrescustefan/bert-base-romanian-cased-v1\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\", num_labels=2)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenize inputs and create datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de206f84835cf647"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebfb2325ebaa2f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = df_train.drop(\"class\", axis=1)\n",
    "y = df_train[\"class\"]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_encodings = tokenizer(list(x_train[\"input\"]), max_length=512, padding=True, truncation=True)\n",
    "val_encodings = tokenizer(list(x_val[\"input\"]), max_length=512, padding=True, truncation=True)\n",
    "\n",
    "train_dataset = CustomDataset(train_encodings, list(y_train))\n",
    "val_dataset = CustomDataset(val_encodings, list(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparam tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6091a466acb128c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91954e23d08bf6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results-v2\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=12,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=1,\n",
    "    learning_rate=1e-7,\n",
    "    optim=\"adamw_torch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428f430e46a57633",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"balanced_accuracy\": balanced_accuracy_score(labels, predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1969f32a873b14",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9046e48b705e16",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9f05177486cc5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"fine-tuned-bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ae66e51a544a231"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318c31ca-ab98-4e24-b95d-dfcf3d11bd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "test_encodings = tokenizer(list(df_test[\"input\"]), max_length=512, padding=True, truncation=True)\n",
    "test_dataset = CustomDataset(test_encodings)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run inference on the test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16ee19821f6f5985"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6adb604-9a09-4678-91a7-3dd2da0b9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        batch_predictions = torch.argmax(probs, dim=1)\n",
    "        predictions.extend(batch_predictions.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51421a9-0b4a-432a-bc5b-cbd1e6eaf16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\"id\": df_test[\"id\"], \"class\": predictions})\n",
    "result_df.to_csv(\"predictions.csv\", index=False, lineterminator=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a9ad17-54ea-4e09-a6ec-cd35d5063e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run inference on the validation set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67df16359854173a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9480d236-3a02-4a2a-9916-42b41a451251",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "model.eval()\n",
    "\n",
    "ids = []\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        labels = batch[\"labels\"]\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        batch_predictions = torch.argmax(probs, dim=1)\n",
    "        predictions.extend(batch_predictions.cpu().numpy())\n",
    "        gt.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d99c2-3be4-4bd5-87f2-cf18e51022dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\"input\": x_val[\"input\"], \"class\": predictions, \"gt\": gt})\n",
    "filtered_df = result_df[result_df[\"class\"] != result_df[\"gt\"]]\n",
    "\n",
    "filtered_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
